{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "print(es.ping())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Index\n",
    "\n",
    "#### What is an Index in Elasticsearch?\n",
    "An index in Elasticsearch is similar to a database in a relational database system. It is a collection of documents that share similar characteristics. Each document is stored as a JSON object and has a unique identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'test_index' created.\n"
     ]
    }
   ],
   "source": [
    "index_name = \"test_index\"\n",
    "\n",
    "if not es.indices.exists(index=index_name):\n",
    "    es.indices.create(index=index_name)\n",
    "    print(f\"Index '{index_name}' created.\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_index': 'test_index', '_id': '1', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 0, '_primary_term': 1}\n"
     ]
    }
   ],
   "source": [
    "doc = {\n",
    "    \"name\": \"John Doe\",\n",
    "    \"age\": 30,\n",
    "    \"occupation\": \"Software Engineer\",\n",
    "    \"location\": \"San Francisco\"\n",
    "}\n",
    "\n",
    "res = es.index(index=index_name, id=1, document=doc)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'took': 16, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 1, 'relation': 'eq'}, 'max_score': 0.5753642, 'hits': [{'_index': 'test_index', '_id': '1', '_score': 0.5753642, '_source': {'name': 'John Doe', 'age': 30, 'occupation': 'Software Engineer', 'location': 'San Francisco'}}]}}\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"occupation\": \"Software Engineer\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res = es.search(index=index_name, body=query)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'_index': 'test_index', '_id': '1', '_version': 2, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 1, '_primary_term': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_query = {\n",
    "    \"doc\": {\n",
    "        \"age\": 31\n",
    "    }\n",
    "}\n",
    "\n",
    "es.update(index=index_name, id=1, body=update_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'_index': 'test_index', '_id': '1', '_version': 3, 'result': 'deleted', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 2, '_primary_term': 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.delete(index=index_name, id=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'took': 1, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 0, 'relation': 'eq'}, 'max_score': None, 'hits': []}, 'aggregations': {'average_age': {'value': None}}}\n"
     ]
    }
   ],
   "source": [
    "aggregation_query = {\n",
    "    \"size\": 0,\n",
    "    \"aggs\": {\n",
    "        \"average_age\": {\n",
    "            \"avg\": {\n",
    "                \"field\": \"age\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res = es.search(index=index_name, body=aggregation_query)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, [])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "# Bulk inserting multiple documents\n",
    "actions = [\n",
    "    {\"_index\": index_name, \"_id\": i, \"_source\": {\"name\": f\"User {i}\", \"age\": 25 + i, \"occupation\": \"Developer\"}}\n",
    "    for i in range(2, 10)\n",
    "]\n",
    "\n",
    "bulk(es, actions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Shard in Elasticsearch?\n",
    "A shard is a subdivision of an index. Each index is split into multiple shards for better performance and fault tolerance.\n",
    "\n",
    "Primary Shards: Store the actual data.\n",
    "Replica Shards: Backup copies of primary shards for redundancy.\n",
    "Each shard is an independent Lucene index that can be stored on a different node in a cluster.\n",
    "\n",
    "Example: How Shards Improve Performance\n",
    "Imagine we have 1 million documents in an index. Instead of storing all of them in a single server, we can distribute them across multiple shards, which can then be placed on different servers (nodes).\n",
    "\n",
    "Creating an Index with Shards and Replicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing index: crime_data\n",
      "Created index: crime_data\n"
     ]
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 3,\n",
    "        \"number_of_replicas\": 1\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"crime_data\"\n",
    "\n",
    "if es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)  # Delete existing index to avoid conflicts\n",
    "    print(f\"Deleted existing index: {index_name}\")\n",
    "\n",
    "es.indices.create(index=index_name, body=index_settings)\n",
    "print(f\"Created index: {index_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65799/1991617153.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna(\"\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "df = pd.read_csv(\"Crime_Data.csv\")\n",
    "df.fillna(\"\", inplace=True)\n",
    "\n",
    "actions = [\n",
    "    {\n",
    "        \"_index\": index_name,\n",
    "        \"_id\": row[\"DR_NO\"],\n",
    "        \"_source\": row.to_dict()\n",
    "    }\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "\n",
    "success, failed = bulk(es, actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharded Index Query Time: 0.0041 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"Crime_Type\": \"Vehicle Stolen\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "res_sharded = es.search(index=\"crime_data\", body=query)\n",
    "sharded_time = time.time() - start_time\n",
    "print(f\"Sharded Index Query Time: {sharded_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'took': 5, 'timed_out': False, '_shards': {'total': 3, 'successful': 3, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 0, 'relation': 'eq'}, 'max_score': None, 'hits': []}}\n"
     ]
    }
   ],
   "source": [
    "print(res_sharded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
